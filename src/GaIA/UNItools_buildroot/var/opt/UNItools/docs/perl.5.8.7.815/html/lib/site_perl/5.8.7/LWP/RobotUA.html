<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<html>
<head>
<!-- saved from url=(0017)http://localhost/ -->
<script language="JavaScript" src="../../../../displayToc.js"></script>
<script language="JavaScript" src="../../../../tocParas.js"></script>
<script language="JavaScript" src="../../../../tocTab.js"></script>
<title>LWP::RobotUA - a class for well-behaved Web robots</title>
<link rel="stylesheet" href="../../../../Active.css" type="text/css" />
<link rev="made" href="mailto:support@ActiveState.com" />
</head>

<body>

<script>writelinks('__top__',4);</script>
<h1><a>LWP::RobotUA - a class for well-behaved Web robots</a></h1>
<p><a name="__index__"></a></p>

<!-- INDEX BEGIN -->

<ul>

	<li><a href="#name">NAME</a></li>
	<li><a href="#synopsis">SYNOPSIS</a></li>
	<li><a href="#description">DESCRIPTION</a></li>
	<li><a href="#methods">METHODS</a></li>
	<li><a href="#see_also">SEE ALSO</a></li>
	<li><a href="#copyright">COPYRIGHT</a></li>
</ul>
<!-- INDEX END -->

<hr />
<p>
</p>
<h1><a name="name">NAME</a></h1>
<p>LWP::RobotUA - a class for well-behaved Web robots</p>
<p>
</p>
<hr />
<h1><a name="synopsis">SYNOPSIS</a></h1>
<pre>
  use LWP::RobotUA;
  my $ua = LWP::RobotUA-&gt;new('my-robot/0.1', 'me@foo.com');
  $ua-&gt;delay(10);  # be very nice -- max one hit every ten minutes!
  ...</pre>
<pre>
  # Then just use it just like a normal LWP::UserAgent:
  my $response = $ua-&gt;get('<a href="http://whatever.int/">http://whatever.int/</a>...');
  ...</pre>
<p>
</p>
<hr />
<h1><a name="description">DESCRIPTION</a></h1>
<p>This class implements a user agent that is suitable for robot
applications.  Robots should be nice to the servers they visit.  They
should consult the <em>/robots.txt</em> file to ensure that they are welcomed
and they should not make requests too frequently.</p>
<p>But before you consider writing a robot, take a look at
&lt;URL:http://www.robotstxt.org/&gt;.</p>
<p>When you use a <em>LWP::RobotUA</em> object as your user agent, then you do not
really have to think about these things yourself; <code>robots.txt</code> files
are automatically consulted and obeyed, the server isn't queried
too rapidly, and so on.  Just send requests
as you do when you are using a normal <em>LWP::UserAgent</em>
object (using <code>$ua-&gt;get(...)</code>, <code>$ua-&gt;head(...)</code>,
<code>$ua-&gt;request(...)</code>, etc.), and this
special agent will make sure you are nice.</p>
<p>
</p>
<hr />
<h1><a name="methods">METHODS</a></h1>
<p>The LWP::RobotUA is a sub-class of LWP::UserAgent and implements the
same methods. In addition the following methods are provided:</p>
<dl>
<dt><strong><a name="item_new">$ua = LWP::RobotUA-&gt;new( %options )</a></strong>

<dt><strong>$ua = LWP::RobotUA-&gt;new( $agent, $from )</strong>

<dt><strong>$ua = LWP::RobotUA-&gt;new( $agent, $from, $rules )</strong>

<dd>
<p>The LWP::UserAgent options <code>agent</code> and <code>from</code> are mandatory.  The
options <a href="#item_delay"><code>delay</code></a>, <a href="#item_use_sleep"><code>use_sleep</code></a> and <a href="#item_rules"><code>rules</code></a> initialize attributes
private to the RobotUA.  If <a href="#item_rules"><code>rules</code></a> are not provided, then
<code>WWW::RobotRules</code> is instantiated providing an internal database of
<em>robots.txt</em>.</p>
</dd>
<dd>
<p>It is also possible to just pass the value of <code>agent</code>, <code>from</code> and
optionally <a href="#item_rules"><code>rules</code></a> as plain positional arguments.</p>
</dd>
</li>
<dt><strong><a name="item_delay">$ua-&gt;delay</a></strong>

<dt><strong>$ua-&gt;delay( $minutes )</strong>

<dd>
<p>Get/set the minimum delay between requests to the same server, in
<em>minutes</em>.  The default is 1 minute.  Note that this number doesn't
have to be an integer; for example, this sets the delay to 10 seconds:</p>
</dd>
<dd>
<pre>
    $ua-&gt;delay(10/60);</pre>
</dd>
</li>
<dt><strong><a name="item_use_sleep">$ua-&gt;use_sleep</a></strong>

<dt><strong>$ua-&gt;use_sleep( $boolean )</strong>

<dd>
<p>Get/set a value indicating whether the UA should <a href="../../../../lib/5.8.7/pod/perlfunc.html#item_sleep"><code>sleep()</code></a> if requests
arrive too fast, defined as $ua-&gt;delay minutes not passed since
last request to the given server.  The default is TRUE.  If this value is
FALSE then an internal SERVICE_UNAVAILABLE response will be generated.
It will have an Retry-After header that indicates when it is OK to
send another request to this server.</p>
</dd>
</li>
<dt><strong><a name="item_rules">$ua-&gt;rules</a></strong>

<dt><strong>$ua-&gt;rules( $rules )</strong>

<dd>
<p>Set/get which <em>WWW::RobotRules</em> object to use.</p>
</dd>
</li>
<dt><strong><a name="item_no_visits">$ua-&gt;no_visits( $netloc )</a></strong>

<dd>
<p>Returns the number of documents fetched from this server host. Yeah I
know, this method should probably have been named <code>num_visits()</code> or
something like that. :-(</p>
</dd>
</li>
<dt><strong><a name="item_host_wait">$ua-&gt;host_wait( $netloc )</a></strong>

<dd>
<p>Returns the number of <em>seconds</em> (from now) you must wait before you can
make a new request to this host.</p>
</dd>
</li>
<dt><strong><a name="item_as_string">$ua-&gt;as_string</a></strong>

<dd>
<p>Returns a string that describes the state of the UA.
Mainly useful for debugging.</p>
</dd>
</li>
</dl>
<p>
</p>
<hr />
<h1><a name="see_also">SEE ALSO</a></h1>
<p><a href="../../../../lib/site_perl/5.8.7/LWP/UserAgent.html">the LWP::UserAgent manpage</a>, <a href="../../../../lib/site_perl/5.8.7/WWW/RobotRules.html">the WWW::RobotRules manpage</a></p>
<p>
</p>
<hr />
<h1><a name="copyright">COPYRIGHT</a></h1>
<p>Copyright 1996-2004 Gisle Aas.</p>
<p>This library is free software; you can redistribute it and/or
modify it under the same terms as Perl itself.</p>

</body>

</html>
